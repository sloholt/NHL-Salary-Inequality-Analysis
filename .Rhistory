# a. Create the list continent_lifeExp
continent_lifeExp <- split(gapminder, gapminder$continent) %>%
lapply(function(df) {
df %>%
group_by(year) %>%
summarise(lifeExp = mean(lifeExp, na.rm = TRUE))
})
print(continent_lifeExp[[1]])
gapminder_summary <- function(year_vector, cat_group, var_group) {
year_vector <- as.integer(year_vector) # Ensure year_vector is integer
# Filter the data for the specified years
filtered_data <- gapminder %>%
filter(year %in% year_vector)
# Group by the specified categorical variable and summarise the specified variables
summary_table <- filtered_data %>%
group_by_(.dots = cat_group) %>%
summarise_at(vars(var_group), list(Avg = mean, Med = median), na.rm = TRUE)
return(summary_table)
}
gapminder_summary(c("1952", "2007"), continent, c("pop", "lifeExp"))
print(gapminder_summary)
gapminder_summary(c("2002"), country, c("lifeExp", "gdpPercap"))[1:10, ]
gapminder_summary <- function(year_vector, cat_group, var_group) {
year_vector <- as.integer(year_vector) # Ensure year_vector is integer
# Filter the data for the specified years
filtered_data <- gapminder %>%
filter(year %in% year_vector)
# Group by the specified categorical variable and summarise the specified variables
summary_table <- filtered_data %>%
group_by_(.dots = cat_group) %>%
summarise_at(vars(var_group), list(Avg = mean, Med = median), na.rm = TRUE)
return(summary_table)
}
gapminder_summary(c("1952", "2007"), continent, c("pop", "lifeExp"))
print(gapminder_summary)
gapminder_summary(c("2002"), country, c("lifeExp", "gdpPercap"))[1:10, ]
gapminder_summary <- function(year_vector, cat_group, var_group) {
year_vector <- as.integer(year_vector) # Ensure year_vector is integer
# Filter the data for the specified years
filtered_data <- gapminder %>%
filter(year %in% year_vector)
# Group by the specified categorical variable and summarise the specified variables
summary_table <- filtered_data %>%
group_by(.dots = cat_group) %>%
summarise_at(vars(var_group), list(Avg = mean, Med = median), na.rm = TRUE)
return(summary_table)
}
gapminder_summary(c("1952", "2007"), continent, c("pop", "lifeExp"))
print(gapminder_summary)
gapminder_summary(c("2002"), country, c("lifeExp", "gdpPercap"))[1:10, ]
#4E:
#I know this is incorrect but the information is correct
print(gapminder_array["1987", , ], digits = 6)
print(gapminder_array["1992", , ], digits = 6)
gapminder_summary <- function(year_vector, cat_group, var_group) {
year_vector <- as.integer(year_vector) # Ensure year_vector is integer
# Filter the data for the specified years
filtered_data <- gapminder %>%
filter(year %in% year_vector)
# Group by the specified categorical variable and summarise the specified variables
summary_table <- filtered_data %>%
group_by_(.dots = cat_group) %>%
summarise_at(vars(var_group), list(Avg = mean, Med = median), na.rm = TRUE)
return(summary_table)
}
gapminder_summary(c("1952", "2007"), continent, c("pop", "lifeExp"))
print(gapminder_summary)
gapminder_summary(c("2002"), country, c("lifeExp", "gdpPercap"))[1:10, ]
gapminder_summary <- function(year_vector, cat_group, var_group) {
year_vector <- as.integer(year_vector) # Ensure year_vector is integer
# Filter the data for the specified years
filtered_data <- gapminder %>%
filter(year %in% year_vector)
# Group by the specified categorical variable and summarise the specified variables
summary_table <- filtered_data %>%
group_by(.dots = cat_group) %>%
summarise_at(vars(var_group), list(Avg = mean, Med = median), na.rm = TRUE)
return(summary_table)
}
gapminder_summary(c("1952", "2007"), continent, c("pop", "lifeExp"))
print(gapminder_summary)
gapminder_summary(c("2002"), country, c("lifeExp", "gdpPercap"))[1:10, ]
gapminder_summary <- function(year_vector, cat_group, var_group) {
year_vector <- as.integer(year_vector) # Ensure year_vector is integer
# Filter the data for the specified years
filtered_data <- gapminder %>%
filter(year %in% year_vector)
# Group by the specified categorical variable and summarise the specified variables
summary_table <- filtered_data %>%
group_by(.dots = cat_group) %>%
summarise_at(vars(var_group), list(Avg = mean, Med = median), na.rm = TRUE)
return(summary_table)
}
gapminder_summary(c("1952", "2007"), continent, c("pop", "lifeExp"))
print(gapminder_summary)
gapminder_summary(c("2002"), "country", c("lifeExp", "gdpPercap"))[1:10, ]
print(gapminder_summary())
#Q3B:
gapminder_summary <- function(year_vector, cat_group, var_group) {
year_vector <- as.integer(year_vector) # Ensure year_vector is integer
# Filter the data for the specified years
filtered_data <- gapminder %>%
filter(year %in% year_vector)
# Group by the specified categorical variable and summarise the specified variables
summary_table <- filtered_data %>%
group_by(.dots = cat_group) %>%
summarise_at(vars(var_group), list(Avg = mean, Med = median), na.rm = TRUE)
return(summary_table)
}
gapminder_summary(c("1952", "2007"), continent, c("pop", "lifeExp"))
gapminder_summary <- function(year_vector, cat_group, var_group) {
year_vector <- as.integer(year_vector) # Ensure year_vector is integer
# Filter the data for the specified years
filtered_data <- gapminder %>%
filter(year %in% year_vector)
# Group by the specified categorical variable and summarise the specified variables
summary_table <- filtered_data %>%
group_by(.dots = cat_group) %>%
summarise_at(vars(var_group), list(Avg = mean, Med = median), na.rm = TRUE)
return(summary_table)
}
gapminder_summary(c("1952", "2007"), continent, c("pop", "lifeExp"))
gapminder_summary <- function(year_vector, cat_group, var_group) {
# Ensure the gapminder data is available
data("gapminder")
# Filter the gapminder data for the specified years
filtered_data <- gapminder %>%
filter(year %in% year_vector)
# Group by the specified categorical variable and year
# Then summarise the specified numerical variables by their mean and median
summary_table <- filtered_data %>%
group_by(year, !!rlang::sym(cat_group)) %>%
summarise_at(vars(one_of(var_group)), list(Avg = mean, Med = median), na.rm = TRUE)
return(summary_table)
}
# Test the function with the provided examples
gapminder_summary(c(1952, 2007), "continent", c("pop", "lifeExp"))
gapminder_summary(c(2002), "country", c("lifeExp", "gdpPercap"))
source("C:/Users/sloan/OneDrive/Desktop/M308_HW1Q1.R")
#Math 308 Homework 1
#Linear Algebra Question 3
#Define the vectors that span U
v1 <- c(0, -1, 2, 0, 2)
v2 <- c(1, -3, 1, -1, 2)
v3 <- c(-1, -3, 5, 0, 7)
v4 <- c(-1, -3, 5, 0, 7)
#Define the vector x
x <- c(-1, -9, -1, 4, 1)
#Apply Gram-Schmidt to get an orthog basis for U
A <- qr.Q(qr(cbind(v1, v2, v3,v4)))
#Find the orthon proj of x onto the subspace
projection <- A %*% (t(A) %*% x)
#Calculate the distance from x to U as the norm of the
#difference between x and its projection
distance <- norm(x - projection, type = "2")
#print results
projection
distance
#Linear Algebra Question 3
#Define the vectors that span U
v1 <- c(0, -1, 2, 0, 2)
v2 <- c(1, -3, 1, -1, 2)
v3 <- c(-1, -3, 5, 0, 7)
v4 <- c(-1, -3, 5, 0, 7)
#Define the vector x
x <- c(-1, -9, -1, 4, 1)
#Apply Gram-Schmidt to get an orthog basis for U
A <- qr.Q(qr(cbind(v1, v2, v3,v4)))
A
#Math 308 Homework 1
#Part 3: PCA Application
# load libraries
library(readr)
library(dplyr)
library(stats)
data.source <- "https://raw.githubusercontent.com/mcgillstat/Regression/main/data/medals_2008.csv"
medals <- read_csv(data.source, col_names = FALSE)
medals <- read_csv(data.source, col_names = c("Country", "Gold", "Silver", "Bronze"))
View(medals)
#Math 308 Homework 1
#Part 3: PCA Application
# load libraries
library(readr)
library(dplyr)
library(stats)
#load data to match tibble
data.source <- "https://raw.githubusercontent.com/mcgillstat/Regression/main/data/medals_2008.csv"
medals <- read_csv(data.source, col_names = FALSE)
medals <- read_csv(data.source, col_names = c("Country", "Gold", "Silver", "Bronze"))
#Part 1: How many nations recieved at lease 1 Gold
nations_with_gold <- sum(medals$Gold >0)
print(nations_with_gold)
#Math 308 Homework 1
#Part 3: PCA Application
# load libraries
library(readr)
library(dplyr)
library(stats)
#load data to match tibble
data.source <- "https://raw.githubusercontent.com/mcgillstat/Regression/main/data/medals_2008.csv"
medals <- read_csv(data.source, col_names = FALSE)
medals <- read_csv(data.source, col_names = c("Country", "Gold", "Silver", "Bronze"))
#Part 1: How many nations recieved at lease 1 Gold
nations_with_gold <- sum(medals$Gold >0)
#result of print(nations_with_gold)
#[1] 69
#Part 2: When do we need to center & scale the data?
#If a data set has large differences between the ranges of initial variables,
#those variables with larger ranges will dominate over those with smaller ranges,
#which can lead to biased results, so we center the data to ensure the PCA
#components are not influenced by the different means of the variables.
#We scale the data to equalize the variance of each variable when the variables
#are measured in different units.
#So, you should center and scale the data before calculating PCA when
#variables are on different scales, you want to ensure variance is due to the
#structure in the data, not the scale of variables, and when you aim to identify
#the directions that capture the most variance, regardless of the original units
#of measurement.
#Part 3: Perform the PCA
#To conduct PCA we need to scale and center the data
medals_scaled <- scale(medals[, c("Gold", "Silver", "Bronze")])
#perform PCA
pca_result <- prcomp(medals_scaled)
#A: Report the 1st, 2nd, 3rd PCA & their corresponding eigenvalues
pca_components <- pca_result$rotation[, 1:3]
pca_eigenvalues <- pca_result$sdev[1:3]^2
print(pca_components)
#Math 308 Homework 1
#Part 3: PCA Application
# load libraries
library(readr)
library(dplyr)
library(stats)
#load data to match tibble
data.source <- "https://raw.githubusercontent.com/mcgillstat/Regression/main/data/medals_2008.csv"
medals <- read_csv(data.source, col_names = FALSE)
medals <- read_csv(data.source, col_names = c("Country", "Gold", "Silver", "Bronze"))
#Part 1: How many nations recieved at lease 1 Gold
nations_with_gold <- sum(medals$Gold >0)
#result of print(nations_with_gold)
#[1] 69
#Part 2: When do we need to center & scale the data?
#If a data set has large differences between the ranges of initial variables,
#those variables with larger ranges will dominate over those with smaller ranges,
#which can lead to biased results, so we center the data to ensure the PCA
#components are not influenced by the different means of the variables.
#We scale the data to equalize the variance of each variable when the variables
#are measured in different units.
#So, you should center and scale the data before calculating PCA when
#variables are on different scales, you want to ensure variance is due to the
#structure in the data, not the scale of variables, and when you aim to identify
#the directions that capture the most variance, regardless of the original units
#of measurement.
#Part 3: Perform the PCA
#To conduct PCA we need to scale and center the data
medals_scaled <- scale(medals[, c("Gold", "Silver", "Bronze")])
#perform PCA
pca_result <- prcomp(medals_scaled)
#A: Report the 1st, 2nd, 3rd PCA & their corresponding eigenvalues
pca_components <- pca_result$rotation[, 1:3]
pca_eigenvalues <- pca_result$sdev[1:3]^2
print(pca_components)
print(pca_eigenvalues)
#Part 4: What is the amount of variance PCA can capture?
#first we need total variance
total_var <- sum(pca_result$sdev^2)
#A: 1st PC, what is corresponding reconstruction error?
#proportion of var for first PCA
pve_1st_pc <- pca_eigenvalues[1] / total_var
#find reconstruction error for first pc
recon_error_1pc <- 1 - pve_1st_pc
print(recon_error_1pc)
print(pca_eigenvalues[1])
#So the amount of variance for the first two is
print(var_captured_1and2)
#B: the first two PC & their reconstruction error:
#variance captured by the 1st & 2nd PC's
var_captured_1and2 <- sum(pca_eigenvalues[1:2])
#proportion of variance for first two PC's
pve_first_two_pcs <- variance_captured_1and2 / total_variance
#B: the first two PC & their reconstruction error:
#variance captured by the 1st & 2nd PC's
var_captured_1and2 <- sum(pca_eigenvalues[1:2])
#proportion of variance for first two PC's
pve_first_two_pcs <- var_captured_1and2 / total_variance
#B: the first two PC & their reconstruction error:
total_var <- sum(pca_result$sdev^2)
#variance captured by the 1st & 2nd PC's
var_captured_1and2 <- sum(pca_eigenvalues[1:2])
#proportion of variance for first two PC's
pve_first_two_pcs <- var_captured_1and2 / total_variance
#B: the first two PC & their reconstruction error:
total_var <- sum(pca_result$sdev^2)
#variance captured by the 1st & 2nd PC's
var_captured_1and2 <- sum(pca_eigenvalues[1:2])
#proportion of variance for first two PC's
pve_first_two_pcs <- var_captured_1and2 / total_var
#reconstruction error for the first two:
recon_error_1pc_2pc <- 1 - pve_first_two_pcs
#So the amount of variance for the first two is
print(var_captured_1and2)
#And their reconstruction error is
print(recon_error_1pc_2pc)
#C: total 3 PC's variance & reconstruction error:
#variance captured by all 3:
var_captured_total <- sum(pca_eigenvalues[1:3])
#proportion of variance for all 3:
pve_total <- var_captured_total / total_var
#reconstruction error total:
recon_error_total <- 1 - pve_total
#So, the variance captured by all 3 PC's is:
print(var_captured_total)
#And their reconstruction error is:
print(recon_error_total)
#projecting observations onto PC1
pc1_scores <- predict(pca_result)[, 1]
#Add PC1 scores to the medals df
medals$PC1_Score <- pc1_scores
#Rank Nations based pn PC1 scores
medals <- medals %>%
arrange(desc(PC1_Score)) %>%
mutate(Rank_PC1 = row_number())
view(medals)
#Part 5: Coordinates of the project obversations
#on PC1 b1 for all nations from original data
#projecting observations onto PC1
pc1_scores <- predict(pca_result)[, 1]
#Add PC1 scores to the medals df
medals$PC1_Score <- pc1_scores
#Rank Nations based pn PC1 scores
medals <- medals %>%
arrange(desc(PC1_Score)) %>%
mutate(Rank_PC1 = row_number())
View(medals)
#Rank nations based on Gold medal counts
medals <- medals %>%
arrange(desc(Gold)) %>%
mutate(Rank_Gold = row_number())
View(medals)
#Rank nations based on total medal counts
medals$Total_Medals <- medals$Gold + Medals$Silver + medals$Bronze
#Rank nations based on total medal counts
medals$Total_Medals <- medals$Gold + medals$Silver + medals$Bronze
medals <- medals %>%
arrange(desc(Total_Medals)) %>%
mutate(Rank_Total = row_number())
View(medals)
print(medals %>% select(Country, Rank_PC1, Rank_Gold, Rank_Total))
tinytex::install_tinytex()
#Math 308 Homework 2 Question 3
#Decoding Info:
#ACB African-Caribbean: African Caribbean in Barbados
#GWD Gambian: Gambian in Western Division, The Gambia
#ESN Esan: Esan in Nigeria
#MSL Mende: Mende in Sierra Leone
#YRI Yoruba: Yoruba in Ibadan, Nigeria
#LWK Luhya: Luhya in Webuye, Kenya
#ASW African-American SW: African Ancestry in Southwest US
#load data
data <- read.table("p4dataset2023.txt", header = FALSE, fill = TRUE,
stringsAsFactors = FALSE)
#find mode
get_mode <- function(v){
uniqv <- unique(v)
uniqv[which.max(tabulate(match(v, uniqv)))]
}
getwd()
setwd("C:\Users\sloan\OneDrive\Desktop\Math308\Homework2")
setwd("C:\Users\sloan\OneDrive\Desktop\Math308\Homework 2")
setwd("C:/Users/sloan/OneDrive/Desktop/Math308/Homework2")
#find mode for each column
modes <- apply(genetic_matrix, 2, get_mode)
install.packages("MPV")
library(MPV)
data(p2.18)
p2.18
View(p2.18)
#Part A: Fit the SLR model to these data
model <- lm(Returned.Impressions ~ Amount.Spent, data=p2.18)
summary(model)
#Part A: Fit the SLR model to these data
model <- lm(Returned.Impressions ~ Amount.Spent, data=p2.18)
summary(model)
#plotting the model:
plot(p2.18$Amount.Spent, p2.18$Returned.Impressions,
main="Simple Linear Regression",
xlab="Amount Spend on Advertising",
ylab ="Returned Impressions",
pch=19)
par(mar = c(4, 4, 2, 2))
#plotting the model:
plot(p2.18$Amount.Spent, p2.18$Returned.Impressions,
main="Simple Linear Regression",
xlab="Amount Spend on Advertising",
ylab ="Returned Impressions",
pch=19)
abline(model, col="blue")
ls
library(MPV)
data(p2.18)
write.csv(p2.18, file = "p2.18.csv", row.names = FALSE)
getwd()
#Math 423 Assignment 4
#Question 1
library(MPV)
data(table.b3)
?table.b3
model <- lm(y, x1+x6, data = data)
model <- lm(y ~ x1+x6, data = data)
model <- lm(y ~ x1+x6, data = mileage_data)
model <- lm(y ~ x1+x6, data = mileage_data)
model <- lm(y ~ x1+x6, data = table.b3)
summary(model)
model_residuals <- residuals(model)
#normality plot
qqnorm(model_residuals, main = "Normal Probability Plot of Residuals")
qqline(model_residuals, col = "purple")
#1.2 residuals vs predicted response
predicted <- predict(model)
plot(predicted, model_residuals,
xlab = "Predicted Values",
ylab = "Residuals",
main = "Residuals vs Predicted Response",
pch = 19, cold = "blue")
#1.2 residuals vs predicted response
predicted <- predict(model)
plot(predicted, model_residuals,
xlab = "Predicted Values",
ylab = "Residuals",
main = "Residuals vs Predicted Response",
pch = 15, cold = "blue")
#1.2 residuals vs predicted response
predicted <- predict(model)
par(mar = c(5, 4, 4, 2))
plot(predicted, model_residuals,
xlab = "Predicted Values",
ylab = "Residuals",
main = "Residuals vs Predicted Response",
pch = 15, cold = "blue")
#1.2 residuals vs predicted response
predicted <- predict(model)
par(mar = c(6, 5, 5, 3))
plot(predicted, model_residuals,
xlab = "Predicted Values",
ylab = "Residuals",
main = "Residuals vs Predicted Response",
pch = 19, cold = "blue")
#1.2 residuals vs predicted response
predicted <- predict(model)
par(mar = c(6, 5, 5, 3))
plot(predicted, model_residuals,
xlab = "Predicted Values",
ylab = "Residuals",
main = "Residuals vs Predicted Response",
pch = 19, col = "blue")
predicted <- predict(model)
par(mar = c(8, 7, 7, 5))
plot(predicted, model_residuals,
xlab = "Predicted Values",
ylab = "Residuals",
main = "Residuals vs Predicted Response",
pch = 19, col = "blue")
abline(h=0, col = "red", lwd = 2)
library(car)
crPlots(model, terms = ~ x1)
par(mar = c(8, 7, 7, 5))
crPlots(model, terms = ~ x1)
studentized_residuals <- rstandard(model)
print(studentized_residuals)
rstudnet_residuals <- rstudent(model)
print(rstudent_residuals)
studentized_residuals <- rstandard(model)
print(studentized_residuals)
rstudent_residuals <- rstudent(model)
print(rstudent_residuals)
getwd()
setwd("C:\\Users\\Sloane\\OneDrive\\Desktop\\project\\NHL-Salary-Inequality-Analysis")
getwd()
#Testing the affect of each inequality measure on ROW
library(readxl)
library(dplyr)
performance <- read_excel("PerformanceTeamData.xlsx")
inequality <- read_excel("Team_Inequality_Measures.xlsx")
colnames(performance)
colnames(inequality)
#Testing the affect of each inequality measure on ROW
library(readxl)
library(dplyr)
performance <- read_excel("PerformanceTeamData.xlsx")
inequality <- read_excel("Team_Inequality_Measures.xlsx")
colnames(performance)
colnames(inequality)
merged_data <- inner_join(performance, inequality, by = c("Team", "Year"))
write.csv(merged_data, "CompleteTeamData.csv", row.names = FALSE)
#SLR modeling ROW as a function of Gini
gini_model <- lm(ROW ~ Gini, data = merged_data)
gini_model <- lm(ROW ~ RawGini, data = merged_data)
summary(gini_model)
#SLR Modeling ROW as a function of Atkinson
atk_model <- lm(ROW ~ Atkinson, data = merged_data)
summary(atk_model)
#SLR Modeling ROW as a function of the Ortega Gamma index
ort_model <- lm(ROW ~ OrtegaGamma, data = merged_data)
summary(ort_model)
#SLR Modeling ROW as a function of all 3
model <- lm(ROW ~ RawGini + Atkinson + OrtegaGamma,
data = merged_data)
summary(model)
#Interaction testing
model_interact <- lm(ROW ~ RawGini * Atkinson + OrtegaGamma,
data = merged_data)
summary(model_interact)
